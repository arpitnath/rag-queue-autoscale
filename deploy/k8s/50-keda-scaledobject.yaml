---
# KEDA ScaledObject for queue-depth autoscaling
# Prerequisites: KEDA must be installed in the cluster
# Install: kubectl apply -f https://github.com/kedacore/keda/releases/download/v2.12.0/keda-2.12.0.yaml

apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: worker-scaledobject
  namespace: rag-demo
spec:
  scaleTargetRef:
    name: worker
  
  # Scaling boundaries
  minReplicaCount: 1
  maxReplicaCount: 20
  
  # Polling and cooldown
  pollingInterval: 10      # Check every 10 seconds
  cooldownPeriod: 60       # Wait 60s before scaling down
  
  # Advanced scaling behavior
  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          # Gradual scale-down to prevent thrashing
          stabilizationWindowSeconds: 120
          policies:
          - type: Percent
            value: 50
            periodSeconds: 60
        scaleUp:
          # Aggressive scale-up for responsiveness
          stabilizationWindowSeconds: 0
          policies:
          - type: Pods
            value: 5
            periodSeconds: 15
          - type: Percent
            value: 100
            periodSeconds: 15
          selectPolicy: Max
  
  triggers:
  # Primary trigger: Queue depth from Prometheus
  - type: prometheus
    metadata:
      # Prometheus server URL (in-cluster)
      serverAddress: http://prometheus.rag-demo.svc:9090
      
      # Metric name for KEDA (used in logs/debugging)
      metricName: agent_queue_depth
      
      # PromQL query to get queue depth
      # Sum across all worker pods
      query: sum(agent_queue_depth{queue="default"})
      
      # Threshold: scale when queue_depth > threshold per replica
      # With threshold=5: 10 jobs in queue = 2 replicas desired
      threshold: "5"
